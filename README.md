# ğŸ›¡ï¸ AutoRail 
The word '*AutoRail*' is **auto**Gen and guard**rail** combined. 
Make LLM's output more consistent with human values, using [AutoGen](https://github.com/microsoft/autogen) and [Guardrails](https://github.com/guardrails-ai/guardrails).

## ğŸ’¡ What the project does
AutoRail is a proof of concept that utilizes AutoGen and Guardrails to align the output of LLMs with human values. It is a project that is still in progress. 
Our goal is to build a complete AI safety framework to evaluate and modify the output text of LLM so that its values align with those of *governments, political parties, and other organizations*.

## ğŸŒŸ Why the project is useful
This project provides a framework to score, evaluatr, and revise the output of LLM. 
We provide a framework and you provide the value documents of your organization. 

## ğŸš€ How users can get started with the project


## ğŸ“‹ Framework details

![AutoRail Overview](doc/images/autorail_overview.png)  

## ğŸ“ Roadmap
- [x] Create a proof of concept
- [x] AutoRail group chat
- [x] Log messages and token cost
- [ ] Convert guardrails to system prompt
- [ ] Azure deployment
- [ ] Write framework details 
- [ ] Package it as a library
<!-- 
- [ ] Write a paper 
- [ ] Cite reference
-->

## ğŸ› ï¸ Contributing
Get started by checking out Github issues and of course using Guardrails to familiarize yourself with the project.
We encourage users to provide **public** value documents.
Convert your value documents into a format that can be used by guardrails. 
