# ğŸ›¡ï¸ AutoRail 
The word '*AutoRail*' is **auto**Gen and guard**rail** combined. 
Make LLM's output more consistent with human values, using [AutoGen](https://github.com/microsoft/autogen) and [Guardrails](https://github.com/guardrails-ai/guardrails).

## ğŸ’¡ What the project does
AutoRail is a proof of concept that utilizes AutoGen and Guardrails to align the output of LLMs with human values. It is a project that is still in progress.
![AutoRail Overview](https://github.com/xrkong/autorail/blob/main/doc/images/autorail_overview.png)
Our goal is to build a complete AI safety framework to evaluate and modify the output text of LLM so that its values align with those of *governments, political parties, and other organizations*.

## ğŸŒŸ Why the project is useful
This project provides a framework to score, evaluatr, and revise the output of LLM. 
We provide a framework and you provide the value documents of your organization. 

## ğŸš€ How users can get started with the project
We encourage users to provide **public** value documents.
Convert your value documents into a format that can be used by guardrails. 

## ğŸ“ Roadmap
- [x] Create a proof of concept
- [x] AutoRail group chat
- [x] Log messages and token cost
- [ ] Convert guardrails to system prompt
- [ ] Azure deployment



